{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import preprocess\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training.full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = preprocess.Preprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "удивительно beebbeebbeebbeebbeebbeeb 詞的超強記憶力 مرره 回目を通\n",
      "['удивительно', 'beebbeebbeebbeebbeebbeeb', '詞的超強記憶力', 'مرره', '回目を通']\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "a = preprocess.Preprocessor()\n",
    "# input_text = \"Taking my folks to the Gospel Brunch at the House of Blues..what a good son I am \"\n",
    "# input_text = \"@Nana_Mex @KellyThomas1  Thanks for the shout Kelly ,Have a great day lol \"\n",
    "# input_text = \"Damn it.  TV on the Radio is playing the Central Park Summer Stage right now, and I didn't know until 30 seconds ago.  \"\n",
    "# input_text = \"I HAVE NO LUCK WAT SO EVA WID CATCHIN ANYBODY ONLINE ON TWITTER!  I TINK IMMA HUDDLE UP IN A CORNER NDD CRY NOW :'(\"\n",
    "# input_text = \"Aw, New Moon looks so bad  Can't wait to see Michael Sheen in it, though!\"\n",
    "# input_text = \"Watching Mickey Rourke in The Wrestler. Gotta see what all the fuss was about. \"\n",
    "# input_text = \"wasn't cant wait for the new hannah motana programmes to come out there gonna be soooo coool! \"\n",
    "# input_text = \"@ChaosMagick Really?! Oh, OK then, just for you   http://twitpic.com/7gk5o\"\n",
    "# input_text = \"I saw the New Moon Trailer/Preview a few hours and minutes ago! It was great! I can't wait to watch New Moon this year!  \"\n",
    "# input_text = \"Re-Readin Eclipse.. Cant wait For New Moon \"\n",
    "# input_text = \"@makelyb excluidinha!!! @Thaaiiis tÃ¡ \"\n",
    "# input_text = \"Looooooooooooooooooong story! sooooooooo excited! soo amazing! Short version: got a splinter in his arm - it got infected because the Drs. staff didn't do their job \"\n",
    "input_text = \"удивительно beebbeebbeebbeebbeebbeeb 詞的超強記憶力 مرره 回目を通\"\n",
    "# input_text = \"\"\n",
    "# input_text = \"\"\n",
    "# input_text = \"\"\n",
    "# input_text = \":( LoL 123 !q @w #e $r %r ^u  &jj *jJ (jkj 0KJ0) -i _j +j {j }j |js :n 'L it's don't Aw Dont Be A Meany  (Susan) Rocls. adfasd Say Hi For Me :L:L\"\n",
    "tmp = a.clean_text(input_text) ; print(tmp)\n",
    "tmp = a.tokenize_text(tmp) ; print(tmp)\n",
    "tmp = a.replace_token_with_index(tmp, a.max_length_dictionary) ; print(tmp)\n",
    "tmp = a.pad_sequence(tmp, a.max_length_tweet) ; print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_json(df, file_path):\n",
    "    progress = 0\n",
    "    result = []\n",
    "    for idx, row in df.iterrows():\n",
    "        progress += 1\n",
    "        if progress%(df.shape[0]//20)==0:\n",
    "            print(progress/(df.shape[0]//20))\n",
    "        \n",
    "        _dict = {}\n",
    "        _dict[\"features\"] = preprocessor.preprocess_text(row[\"Tweet\"])\n",
    "        _dict[\"sentiment\"] = row[\"Sentiment\"]\n",
    "        result.append(_dict)\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        for entry in result:\n",
    "            json.dump(entry, f)\n",
    "            f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.sample(frac=0.95,random_state=200)\n",
    "df_eval = df.drop(df_train.index)\n",
    "df_dev = df_train.sample(frac=0.10/0.95, random_state=200)\n",
    "df_train = df_train.drop(df_dev.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n",
      "0.1\n",
      "0.05\n"
     ]
    }
   ],
   "source": [
    "# check portion\n",
    "print(df_train.shape[0]/df.shape[0])\n",
    "print(df_dev.shape[0]/df.shape[0])\n",
    "print(df_eval.shape[0]/df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5003235294117647\n",
      "0.49775625\n",
      "0.4989875\n"
     ]
    }
   ],
   "source": [
    "# check distribution\n",
    "print(df.loc[df[\"Sentiment\"]==0].shape[0]/df.shape[0])\n",
    "print(df_train.loc[df_train[\"Sentiment\"]==0].shape[0]/df_train.shape[0])\n",
    "print(df_dev.loc[df_dev[\"Sentiment\"]==0].shape[0]/df_dev.shape[0])\n",
    "print(df_eval.loc[df_eval[\"Sentiment\"]==0].shape[0]/df_eval.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dataframe\n",
    "df_train.to_csv(\"complete/train.csv\", index=False)\n",
    "df_dev.to_csv(\"complete/dev.csv\", index=False)\n",
    "df_eval.to_csv(\"complete/eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "13.0\n",
      "14.0\n",
      "15.0\n",
      "16.0\n",
      "17.0\n",
      "18.0\n",
      "19.0\n",
      "20.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "13.0\n",
      "14.0\n",
      "15.0\n",
      "16.0\n",
      "17.0\n",
      "18.0\n",
      "19.0\n",
      "20.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "convert_to_json(df_eval, \"complete/eval.json\")\n",
    "convert_to_json(df_dev, \"complete/dev.json\")\n",
    "convert_to_json(df_train, \"complete/train.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split 1/10 of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n",
      "0.1\n",
      "0.05\n",
      "0.50113125\n",
      "0.5007720588235294\n",
      "0.5041875\n",
      "0.501125\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac=0.1,random_state=200)\n",
    "\n",
    "df_train = df.sample(frac=0.95,random_state=200)\n",
    "df_eval = df.drop(df_train.index)\n",
    "df_dev = df_train.sample(frac=0.10/0.95, random_state=200)\n",
    "df_train = df_train.drop(df_dev.index)\n",
    "\n",
    "# check portion\n",
    "print(df_train.shape[0]/df.shape[0])\n",
    "print(df_dev.shape[0]/df.shape[0])\n",
    "print(df_eval.shape[0]/df.shape[0])\n",
    "\n",
    "# check distribution\n",
    "print(df.loc[df[\"Sentiment\"]==0].shape[0]/df.shape[0])\n",
    "print(df_train.loc[df_train[\"Sentiment\"]==0].shape[0]/df_train.shape[0])\n",
    "print(df_dev.loc[df_dev[\"Sentiment\"]==0].shape[0]/df_dev.shape[0])\n",
    "print(df_eval.loc[df_eval[\"Sentiment\"]==0].shape[0]/df_eval.shape[0])\n",
    "\n",
    "df_train.to_csv(\"one_tenth/train.csv\", index=False)\n",
    "df_dev.to_csv(\"one_tenth/dev.csv\", index=False)\n",
    "df_eval.to_csv(\"one_tenth/eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "13.0\n",
      "14.0\n",
      "15.0\n",
      "16.0\n",
      "17.0\n",
      "18.0\n",
      "19.0\n",
      "20.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "13.0\n",
      "14.0\n",
      "15.0\n",
      "16.0\n",
      "17.0\n",
      "18.0\n",
      "19.0\n",
      "20.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "13.0\n",
      "14.0\n",
      "15.0\n",
      "16.0\n",
      "17.0\n",
      "18.0\n",
      "19.0\n"
     ]
    }
   ],
   "source": [
    "convert_to_json(df_eval, \"one_tenth/eval.json\")\n",
    "convert_to_json(df_dev, \"one_tenth/dev.json\")\n",
    "convert_to_json(df_train, \"one_tenth/train.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split 1/5 of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n",
      "0.1\n",
      "0.05\n",
      "0.4995875\n",
      "0.49969117647058825\n",
      "0.498625\n",
      "0.49975\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac=0.2,random_state=200)\n",
    "\n",
    "df_train = df.sample(frac=0.95,random_state=200)\n",
    "df_eval = df.drop(df_train.index)\n",
    "df_dev = df_train.sample(frac=0.10/0.95, random_state=200)\n",
    "df_train = df_train.drop(df_dev.index)\n",
    "\n",
    "# check portion\n",
    "print(df_train.shape[0]/df.shape[0])\n",
    "print(df_dev.shape[0]/df.shape[0])\n",
    "print(df_eval.shape[0]/df.shape[0])\n",
    "\n",
    "# check distribution\n",
    "print(df.loc[df[\"Sentiment\"]==0].shape[0]/df.shape[0])\n",
    "print(df_train.loc[df_train[\"Sentiment\"]==0].shape[0]/df_train.shape[0])\n",
    "print(df_dev.loc[df_dev[\"Sentiment\"]==0].shape[0]/df_dev.shape[0])\n",
    "print(df_eval.loc[df_eval[\"Sentiment\"]==0].shape[0]/df_eval.shape[0])\n",
    "\n",
    "df_train.to_csv(\"one_fifth/train.csv\", index=False)\n",
    "df_dev.to_csv(\"one_fifth/dev.csv\", index=False)\n",
    "df_eval.to_csv(\"one_fifth/eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "13.0\n",
      "14.0\n",
      "15.0\n",
      "16.0\n",
      "17.0\n",
      "18.0\n",
      "19.0\n",
      "20.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "13.0\n",
      "14.0\n",
      "15.0\n",
      "16.0\n",
      "17.0\n",
      "18.0\n",
      "19.0\n",
      "20.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "13.0\n",
      "14.0\n",
      "15.0\n",
      "16.0\n",
      "17.0\n",
      "18.0\n",
      "19.0\n",
      "20.0\n"
     ]
    }
   ],
   "source": [
    "convert_to_json(df_eval, \"one_fifth/eval.json\")\n",
    "convert_to_json(df_dev, \"one_fifth/dev.json\")\n",
    "convert_to_json(df_train, \"one_fifth/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
