{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import preprocess\n",
    "import pandas as pd\n",
    "import json\n",
    "# https://towardsdatascience.com/cnn-sentiment-analysis-1d16b7c5a0e7\n",
    "# https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/reports/custom/15786247.pdf\n",
    "# https://medium.com/swlh/determining-the-happiest-cities-using-twitter-sentiment-analysis-with-bert-67b7591e593\n",
    "# https://www.kaggle.com/menion/sentiment-analysis-with-bert-87-accuracy/notebook\n",
    "tf.__version__\n",
    "# from tensorflow.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "\n",
    "with open(\"eval.json\", \"r\") as file:\n",
    "    for line in file:\n",
    "        entry = json.loads(line)\n",
    "        labels.append(entry[\"sentiment\"] / 4)\n",
    "        features.append(entry[\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_model = tf.keras.models.load_model(\"benchmark/1\")\n",
    "result = benchmark_model.evaluate(np.array(features), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_model = tf.keras.models.load_model(\"standard-cloud/1\")\n",
    "result = standard_model.evaluate(np.array(features), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.load_model(\"2-layer-lstm-dropout/1\")\n",
    "result = lstm_model.evaluate(np.array(features), np.array(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# translate spanish into english\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looooooooooooooooooong story  sooooooooo excited  soo amazing  short version  got a splinter in his arm   it got infected because the drs  staff didnt do their job\n",
      "['looong', 'story', 'sooo', 'excited', 'soo', 'amazing', 'short', 'version', 'got', 'a', 'splinter', 'in', 'his', 'arm', 'it', 'got', 'infected', 'because', 'the', 'drs', 'staff', 'didnt', 'do', 'their', 'job']\n",
      "[68091, 941, 285594, 872, 1662, 567, 1570, 2792, 145, 13, 73132, 37, 251, 4801, 35, 145, 41410, 269, 15, 71743, 6375, 1838, 45, 352, 770]\n",
      "[68091, 941, 285594, 872, 1662, 567, 1570, 2792, 145, 13, 73132, 37, 251, 4801, 35, 145, 41410, 269, 15, 71743, 6375, 1838, 45, 352, 770, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "a = preprocess.Preprocessor(max_length_tweet=30)\n",
    "# input_text = \"Taking my folks to the Gospel Brunch at the House of Blues..what a good son I am \"\n",
    "# input_text = \"@Nana_Mex @KellyThomas1  Thanks for the shout Kelly ,Have a great day lol \"\n",
    "# input_text = \"Damn it.  TV on the Radio is playing the Central Park Summer Stage right now, and I didn't know until 30 seconds ago.  \"\n",
    "# input_text = \"I HAVE NO LUCK WAT SO EVA WID CATCHIN ANYBODY ONLINE ON TWITTER!  I TINK IMMA HUDDLE UP IN A CORNER NDD CRY NOW :'(\"\n",
    "# input_text = \"Aw, New Moon looks so bad  Can't wait to see Michael Sheen in it, though!\"\n",
    "# input_text = \"Watching Mickey Rourke in The Wrestler. Gotta see what all the fuss was about. \"\n",
    "# input_text = \"wasn't cant wait for the new hannah motana programmes to come out there gonna be soooo coool! \"\n",
    "# input_text = \"@ChaosMagick Really?! Oh, OK then, just for you   http://twitpic.com/7gk5o\"\n",
    "# input_text = \"I saw the New Moon Trailer/Preview a few hours and minutes ago! It was great! I can't wait to watch New Moon this year!  \"\n",
    "# input_text = \"Re-Readin Eclipse.. Cant wait For New Moon \"\n",
    "# input_text = \"@makelyb excluidinha!!! @Thaaiiis tÃ¡ \"\n",
    "# input_text = \"Looooooooooooooooooong story! sooooooooo excited! soo amazing! Short version: got a splinter in his arm - it got infected because the Drs. staff didn't do their job \"\n",
    "# input_text = \"\"\n",
    "# input_text = \"\"\n",
    "# input_text = \"\"\n",
    "# input_text = \"\"\n",
    "# input_text = \":( LoL 123 !q @w #e $r %r ^u  &jj *jJ (jkj 0KJ0) -i _j +j {j }j |js :n 'L it's don't Aw Dont Be A Meany  (Susan) Rocls. adfasd Say Hi For Me :L:L\"\n",
    "tmp = a.clean_text(input_text) ; print(tmp)\n",
    "tmp = a.tokenize_text(tmp) ; print(tmp)\n",
    "tmp = a.replace_token_with_index(tmp, a.max_length_dictionary) ; print(tmp)\n",
    "tmp = a.pad_sequence(tmp, a.max_length_tweet) ; print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done: to lower character\n",
    "# done: no comma, hyphen, question mark etc.\n",
    "# done: no numbers\n",
    "# done: shorten the words - awww ---> keep those in the dictionary\n",
    "# :p, :'(, :(\n",
    "# done: wasn't, I'd\n",
    "# translate spanish into english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# examine the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"dict/glove_dict_minimum_all.txt\", \"r\", encoding='utf-8')\n",
    "dictionary = {}\n",
    "keys = []\n",
    "for word_vector in file:\n",
    "    dictionary[word_vector.split()[0]] = word_vector.split()[1:]\n",
    "    keys.append(word_vector.split()[0])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"fc\" in keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
